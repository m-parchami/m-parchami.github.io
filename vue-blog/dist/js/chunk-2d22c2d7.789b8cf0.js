(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["chunk-2d22c2d7"],{f1b8:function(e,s,t){"use strict";t.r(s);var a=function(){var e=this,s=e.$createElement;e._self._c;return e._m(0)},n=[function(){var e=this,s=e.$createElement,t=e._self._c||s;return t("section",[t("h1",[e._v("Build your own Green Screen!")]),t("p",[e._v("Hey there!\nIn this tutorial I will try to help you get familiar with background subtraction, and some morphological operations. Then to see the results in practice, we will build our own green screen ;). If you have already bought a green screen don't worry, it is really unlikely that this method with this level of simplicity will out perform your actual one.")]),t("h1",[e._v("What is Background Subtraction and why bother?")]),t("p",[e._v("Background Subtraction has been attracting many Computer Vision scientists in the past years. In my opinion, it mainly consists of two steps. Measuring the background, that is knowing the value each pixel must have to construct the background image. The second step is to process the differences of a frame and the stored background image and get the good stuff. Imagine a security guard staring multiple monitors every second to find out whether there's a change in the scene (someone passing by etc.), however, with the help of background subtraction and some further processings, the guard can just wait for an alarm that indicates a change in the scene. This can even be used to reduce the amound of storage needed to keep the security tapes. The time periods that scene remains stable can be cut easily.")]),t("h2",[e._v("Getting the background image")]),t("p",[e._v("Depending on the situations and use cases, background measurement can be tricky. In an easy case, we assume that the scene itself is not changing at all. Not even in illumination. Therefore we can assume the pixel intensities will almost keep the same values over periods of time. But even with this, we can't be sure on what's the correct pixel value. The camera noise, no matter what restrictions you assume, are always there. Even with a fixed camera and a static scene, you can see the pixel values keep changing. This noise can harm our process in two ways. First, finding the right pixel value, and Second, deciding whether the change must be considered as new object.")]),t("h3",[e._v("A Quick Solution!")]),t("p",[e._v("One of the easiest solutions is to avoid constructing background from a single image. We can use a short sequence of frames (remember the security camera example) and conclude the background image in a more robust manner. Since the camera noise often has Normal Distribution, using median (or even averaging) in a sequence of values will eventually discard the noise. Therefore all we need to do is to store couple of frames, do pixel-wise median over the sequence, and valla, a much more clean background image will be smiling at you. This is also great when the background itself tends to change gradually. It will take just a couple of frames to have the updated version.")]),t("h3",[e._v("Enough talking, show me the code!")]),t("p",[e._v("Alright let's see how easy it really is to get the background image with this trick. As I mentioned this method will require a few background frames to overcome the noise. So, we define a mode for capturing these background frames. We switch the modes with 'b' button.")]),t("pre",{pre:!0},[t("code",{pre:!0,attrs:{"v-pre":"",class:"language-python"}},[t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("import")]),e._v(" cv2\n"),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("import")]),e._v(" numpy "),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("as")]),e._v(" np\n\ncap = cv2.VideoCapture("),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("0")]),e._v(") "),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# If you have an additional webcam you may change this line")]),e._v("\nbuffer = []\nmode = "),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"capture"')]),e._v("\nbackground = "),t("span",{pre:!0,attrs:{class:"hljs-literal"}},[e._v("None")]),e._v("\nthreshold = "),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("70")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("while")]),e._v(" "),t("span",{pre:!0,attrs:{class:"hljs-literal"}},[e._v("True")]),e._v(":\n    ok, frame = cap.read()\n    "),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("if")]),e._v(" "),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("not")]),e._v(" ok:\n\t    print("),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"Capture Ended!"')]),e._v(")\n\t    "),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("break")]),e._v("\n\tcv2.imshow("),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"camera"')]),e._v(", frame)\n\tkey = cv2.waitKey("),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("1")]),e._v(") & "),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("0xFF")]),e._v(" "),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# You may change this line if you need a specific FPS")]),e._v("\n\t"),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("if")]),e._v(" key == ord("),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v("'b'")]),e._v("):\n\t\t"),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("if")]),e._v(" mode == "),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"background"')]),e._v(":  "),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# If it was taking background till now:")]),e._v("\n\n\t        "),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# Compute background and go to capture mode")]),e._v("\n\t\t\tbackground = np.median(buffer, axis = "),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("0")]),e._v(")\n\n\t\t\t"),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# In case you used other methods resulting in floating point pixels:")]),e._v("\n\t        background = np.asarray(background, dtype = np.uint8)\n\n\t\t\t"),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# Background is done, go to the capture (normal) mode")]),e._v("\n\t        mode = "),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"capture"')]),e._v("\n\n\t    "),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("else")]),e._v(":\n\t        "),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# Free the buffer for new background computation")]),e._v("\n\t\t\tbuffer = []\n\n\t\t\t"),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# Switch the mode")]),e._v("\n\t        mode = "),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"background"')]),e._v("\n\n\t"),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("elif")]),e._v(" key == ord("),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v("'q'")]),e._v("): "),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# Just for ending the cycle")]),e._v("\n       \t    "),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("break")]),e._v("\n")])]),t("p",[e._v("Ok now we have the code to compute the background. Let's go through storing and showing the background frames.")]),t("pre",{pre:!0},[t("code",{pre:!0,attrs:{"v-pre":"",class:"language-Python"}},[e._v("\t"),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("if")]),e._v(" mode == "),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"background"')]),e._v(":\n\t    buffer.append(frame)\n\t"),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("if")]),e._v(" background "),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("is")]),e._v(" "),t("span",{pre:!0,attrs:{class:"hljs-keyword"}},[e._v("not")]),e._v(" "),t("span",{pre:!0,attrs:{class:"hljs-literal"}},[e._v("None")]),e._v(": "),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# We have a background computed")]),e._v("\n\t\t"),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# This is just for you to check the computed background, comment these in later usages.")]),e._v("\n\t\tcv2.imshow("),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"background"')]),e._v(", background)\n\t\tcv2.waitKey("),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("1")]),e._v(")\n")])]),t("p",[e._v("Ok now we have the background image. The next step is to subtract each frame from our background to get the green screen like output.\nFirst we compute absolute difference between two images( captured frame and previously computer background). Then, in order to remove differences caused by noise, we apply a threshold to this difference. Unfortunately, this will not be enough to fix all of the noises. To do so, we take advantage of already implemented morphological operations in OpenCV. Make sure you read the docs properly. I will try to add images of each operation in the future.")]),t("pre",{pre:!0},[t("code",{pre:!0,attrs:{"v-pre":"",class:"language-Python"}},[e._v("\n\t\tsub_image = cv2.absdiff(frame, background)\n                sub_image = np.sum(sub_image, axis="),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("2")]),e._v(")\n\n\t\tbinary = np.zeros(sub_image.shape, dtype=np.uint8)\n\t\tbinary[sub_image > threshold] = "),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("1")]),e._v("\n\n\t\tkernel = np.ones(("),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("5")]),e._v(", "),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("5")]),e._v("), np.uint8)\n\t\tbinary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n\t\tkernel = np.ones(("),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("17")]),e._v(", "),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("17")]),e._v("), np.uint8)\n\t\tbinary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n\n\t\tmasked_frame = frame.copy()\n\t\tmasked_frame[binary == "),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("0")]),e._v("] = "),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("0")]),e._v("\n\t\tcv2.imshow("),t("span",{pre:!0,attrs:{class:"hljs-string"}},[e._v('"masked"')]),e._v(", masked_frame)  "),t("span",{pre:!0,attrs:{class:"hljs-comment"}},[e._v("# This is the final output")]),e._v("\n\t\tcv2.waitKey("),t("span",{pre:!0,attrs:{class:"hljs-number"}},[e._v("1")]),e._v(")\n")])]),t("p",[t("a",{attrs:{href:""}},[e._v("img1")])])])}],r=t("2877"),o={},i=Object(r["a"])(o,a,n,!1,null,null,null);s["default"]=i.exports}}]);
//# sourceMappingURL=chunk-2d22c2d7.789b8cf0.js.map
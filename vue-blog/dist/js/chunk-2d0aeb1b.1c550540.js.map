{"version":3,"sources":["webpack:///./src/markdowns/magic-webcam.md?c77a","webpack:///./src/markdowns/magic-webcam.md"],"names":["render","_vm","this","_h","$createElement","_self","_c","_m","staticRenderFns","_v","pre","attrs","script","component"],"mappings":"yHAAA,IAAIA,EAAS,WAAa,IAAIC,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAII,MAAMC,GAAO,OAAOL,EAAIM,GAAG,IACnGC,EAAkB,CAAC,WAAa,IAAIP,EAAIC,KAASC,EAAGF,EAAIG,eAAmBE,EAAGL,EAAII,MAAMC,IAAIH,EAAG,OAAOG,EAAG,UAAU,CAACA,EAAG,IAAI,CAACL,EAAIQ,GAAG,QAAQH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,qBAAqBR,EAAIQ,GAAG,0JAA0JH,EAAG,SAAS,CAACL,EAAIQ,GAAG,YAAYR,EAAIQ,GAAG,iCAAiCH,EAAG,IAAI,CAACK,MAAM,CAAC,KAAO,2DAA2D,CAACV,EAAIQ,GAAG,WAAWR,EAAIQ,GAAG,OAAOH,EAAG,IAAI,CAACL,EAAIQ,GAAG,yBAAyBH,EAAG,MAAM,CAACI,KAAI,GAAM,CAACJ,EAAG,OAAO,CAACI,KAAI,EAAKC,MAAM,CAAC,QAAQ,KAAK,CAACV,EAAIQ,GAAG,6BAA6BH,EAAG,IAAI,CAACL,EAAIQ,GAAG,8EAA8EH,EAAG,IAAI,CAACL,EAAIQ,GAAG,qQAAuQH,EAAG,SAAS,CAACL,EAAIQ,GAAG,cAAcR,EAAIQ,GAAG,MAAMH,EAAG,SAAS,CAACL,EAAIQ,GAAG,eAAeR,EAAIQ,GAAG,UAAUH,EAAG,SAAS,CAACL,EAAIQ,GAAG,iBAAiBR,EAAIQ,GAAG,SAASH,EAAG,SAAS,CAACL,EAAIQ,GAAG,kBAAkBR,EAAIQ,GAAG,oBAAoBH,EAAG,IAAI,CAACL,EAAIQ,GAAG,mvBAAmvBH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,YAAYR,EAAIQ,GAAG,SAASH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,YAAYR,EAAIQ,GAAG,iBAAiBH,EAAG,KAAK,CAACL,EAAIQ,GAAG,YAAYH,EAAG,IAAI,CAACL,EAAIQ,GAAG,8QAA8QH,EAAG,IAAI,CAACL,EAAIQ,GAAG,0BAA0BH,EAAG,IAAI,CAACK,MAAM,CAAC,KAAO,6CAA6C,CAACV,EAAIQ,GAAG,kBAAkBR,EAAIQ,GAAG,uIAAuIH,EAAG,IAAI,CAACK,MAAM,CAAC,KAAO,wJAAwJ,CAACV,EAAIQ,GAAG,cAAcR,EAAIQ,GAAG,sEAAsEH,EAAG,IAAI,CAACL,EAAIQ,GAAG,mCAAmCH,EAAG,MAAM,CAACI,KAAI,GAAM,CAACJ,EAAG,OAAO,CAACI,KAAI,EAAKC,MAAM,CAAC,QAAQ,KAAK,CAACV,EAAIQ,GAAG,4HAA4HH,EAAG,KAAK,CAACL,EAAIQ,GAAG,YAAYH,EAAG,IAAI,CAACL,EAAIQ,GAAG,8LAA8LH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,6CAA6CH,EAAG,MAAM,CAACI,KAAI,GAAM,CAACJ,EAAG,OAAO,CAACI,KAAI,EAAKC,MAAM,CAAC,QAAQ,KAAK,CAACV,EAAIQ,GAAG,qGAAqGH,EAAG,IAAI,CAACL,EAAIQ,GAAG,gGAAgGH,EAAG,MAAM,CAACI,KAAI,GAAM,CAACJ,EAAG,OAAO,CAACI,KAAI,EAAKC,MAAM,CAAC,QAAQ,KAAK,CAACV,EAAIQ,GAAG,qDAAqDH,EAAG,KAAK,CAACL,EAAIQ,GAAG,YAAYH,EAAG,IAAI,CAACL,EAAIQ,GAAG,wPAAwPH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,cAAcR,EAAIQ,GAAG,kCAAkCH,EAAG,SAAS,CAACL,EAAIQ,GAAG,YAAYR,EAAIQ,GAAG,uFAAuFH,EAAG,IAAI,CAACL,EAAIQ,GAAG,wBAAwBH,EAAG,MAAM,CAACI,KAAI,GAAM,CAACJ,EAAG,OAAO,CAACI,KAAI,EAAKC,MAAM,CAAC,QAAQ,KAAK,CAACV,EAAIQ,GAAG,iCAAiCH,EAAG,IAAI,CAACL,EAAIQ,GAAG,+HAA+HH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,kBAAkBR,EAAIQ,GAAG,sBAAsBH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,eAAeR,EAAIQ,GAAG,cAAcH,EAAG,IAAI,CAACL,EAAIQ,GAAG,6BAA6BH,EAAG,MAAM,CAACI,KAAI,GAAM,CAACJ,EAAG,OAAO,CAACI,KAAI,EAAKC,MAAM,CAAC,QAAQ,KAAK,CAACV,EAAIQ,GAAG,oOAAoOH,EAAG,IAAI,CAACL,EAAIQ,GAAG,4EAA4EH,EAAG,IAAI,CAACL,EAAIQ,GAAG,QAAQH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,gBAAgBR,EAAIQ,GAAG,2EAA2EH,EAAG,OAAO,CAACI,KAAI,GAAM,CAACT,EAAIQ,GAAG,gBAAgBR,EAAIQ,GAAG,2IAA2IH,EAAG,IAAI,CAACL,EAAIQ,GAAG,iB,YCAljLG,EAAS,GAKTC,EAAY,eACdD,EACAZ,EACAQ,GACA,EACA,KACA,KACA,MAIa,aAAAK,E","file":"js/chunk-2d0aeb1b.1c550540.js","sourcesContent":["var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',[_c('p',[_vm._v(\"The \"),_c('code',{pre:true},[_vm._v(\"magic_webcam.py\")]),_vm._v(\" can be used for presenting a paper on your desk or a close-enough whiteboard. Besides the packages mentioned in the following, you also need to have \"),_c('strong',[_vm._v(\"OpenCV\")]),_vm._v(\" installed. You can use this \"),_c('a',{attrs:{\"href\":\"https://www.learnopencv.com/install-opencv3-on-ubuntu/\"}},[_vm._v(\"guide\")]),_vm._v(\".\")]),_c('p',[_vm._v(\"Run the code using:\")]),_c('pre',{pre:true},[_c('code',{pre:true,attrs:{\"v-pre\":\"\"}},[_vm._v(\"python magic_cam.py\\n\")])]),_c('p',[_vm._v(\"As long as you have OpenCV installed, the python version doesn't matter.\")]),_c('p',[_vm._v(\"After running the script, if everything goes well, you will see a \\\"calibration\\\" window. On this window, you must specify 4 points using your left mouse button. These points will be used for a perspective transformation. The selected coordinates will become \"),_c('strong',[_vm._v(\"Top Left\")]),_vm._v(\", \"),_c('strong',[_vm._v(\"Top Right\")]),_vm._v(\", and \"),_c('strong',[_vm._v(\"Bottom Left\")]),_vm._v(\" and \"),_c('strong',[_vm._v(\"Bottom Right\")]),_vm._v(\" respectively.\")]),_c('p',[_vm._v(\"As you can see, the output of this code can be viewed in an OpenCV window. Unfortunately, that's not always the case! You may also want to share the output in an online platform such as Skype(or any other application which uses your webcam). Of course, you can always use the \\\"screen sharing\\\" feature provided by the platform itself, however,  it would take too much unnecessary bandwidth and also, lower your computer's performance during the presentation. In the following, I will provide you a fairly simple way to stream this output(transformed images) as a fake webcam.\\nThese instructions will work on Linux. Of course, you can still use the basic functionality(perspective transformation resulting in a window) on any operating system having \"),_c('code',{pre:true},[_vm._v(\"python\")]),_vm._v(\" and \"),_c('code',{pre:true},[_vm._v(\"OpenCV\")]),_vm._v(\" installed.\")]),_c('h1',[_vm._v(\"Step 1\")]),_c('p',[_vm._v(\"First of all, we need a video device. Almost all of the applications using your webcam, will automatically search your computer's video devices and provide you a list of cameras to use. Therefore, we will create a new one to let it be useable in such applications.\")]),_c('p',[_vm._v(\"To do so, we will use \"),_c('a',{attrs:{\"href\":\"https://github.com/umlaeute/v4l2loopback\"}},[_vm._v(\"v4l2loopback\")]),_vm._v(\". There's a great detailed guide on their README to help you install their module. I also took hints from the first answer on this \"),_c('a',{attrs:{\"href\":\"https://unix.stackexchange.com/questions/528400/how-can-i-stream-my-desktop-screen-to-dev-video1-as-a-fake-webcam-on-linux?answertab=active#tab-top\"}},[_vm._v(\"question\")]),_vm._v(\". Make sure you install this module somewhere accessible enough!\")]),_c('p',[_vm._v(\"Here are the commands I used:\")]),_c('pre',{pre:true},[_c('code',{pre:true,attrs:{\"v-pre\":\"\"}},[_vm._v(\"git clone https://github.com/umlaeute/v4l2loopback/\\ncd v4l2loopback\\nsudo make\\nsudo make install\\nsudo depmod -a\\n\")])]),_c('h1',[_vm._v(\"Step 2\")]),_c('p',[_vm._v(\"Now that the module is set, we must create our new video device. Keep in mind that you should run the following commands every time you reboot your Linux from the installation directory \"),_c('code',{pre:true},[_vm._v(\"[Your installation path]/v4l2loopback\")])]),_c('pre',{pre:true},[_c('code',{pre:true,attrs:{\"v-pre\":\"\"}},[_vm._v(\"sudo modprobe videodev\\nsudo insmod ./v4l2loopback.ko devices=1 video_nr=1 exclusive_caps=1\\n\")])]),_c('p',[_vm._v(\"Now we must check whether the device is created. You can use either of the below commands:\")]),_c('pre',{pre:true},[_c('code',{pre:true,attrs:{\"v-pre\":\"\"}},[_vm._v(\"ls -al /dev/video*\\nv4l2-ctl --list-devices\\n\")])]),_c('h1',[_vm._v(\"Step 3\")]),_c('p',[_vm._v(\"Now we have our device, you may already be able to see it in the list of available webcams in different applications. But the problem is that it's not currently streaming any data. So let's fix it. instead of showing each processed frame using \"),_c('code',{pre:true},[_vm._v(\"imshow()\")]),_vm._v(\", we will pipe the data to an \"),_c('strong',[_vm._v(\"ffmpeg\")]),_vm._v(\" command. The command will stream the frames into the newly created video device.\")]),_c('p',[_vm._v(\"To install ffmpeg:\")]),_c('pre',{pre:true},[_c('code',{pre:true,attrs:{\"v-pre\":\"\"}},[_vm._v(\"sudo apt install ffmpeg\\n\")])]),_c('p',[_vm._v(\"Now that we got everything set, the only thing left is to pipe the output to the right ffmpeg command. To enable piping on \"),_c('code',{pre:true},[_vm._v(\"magic_cam.py\")]),_vm._v(\", we will use the \"),_c('code',{pre:true},[_vm._v(\"--pipe on\")]),_vm._v(\" option.\")]),_c('p',[_vm._v(\"So the command will be:\")]),_c('pre',{pre:true},[_c('code',{pre:true,attrs:{\"v-pre\":\"\"}},[_vm._v(\"python magic_webcam.py --pipe on| ffmpeg -f rawvideo -pixel_format rgb24 -video_size 1280x720 -framerate 30 -i - -vcodec rawvideo -pix_fmt yuv420p -threads 0 -f v4l2 -vf 'scale=1280:720' -pixel_format rgb24 /dev/video1\\n\")])]),_c('p',[_vm._v(\"Don't forget to change the scale configuration based on your situation\")]),_c('p',[_vm._v(\"The \"),_c('code',{pre:true},[_vm._v(\"fastcam.py\")]),_vm._v(\" is the same script which you can find outside of this directory named \"),_c('code',{pre:true},[_vm._v(\"goodcam.py\")]),_vm._v(\". It's been used for better fps and lower delay. To be short, it uses a separate thread for reading the frames from the video source.\")]),_c('p',[_vm._v(\"cheers.\")])])}]\n\nexport { render, staticRenderFns }","import { render, staticRenderFns } from \"./magic-webcam.md?vue&type=template&id=e48f8bd8&\"\nvar script = {}\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports"],"sourceRoot":""}